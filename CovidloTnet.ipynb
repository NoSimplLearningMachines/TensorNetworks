{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting COVID-19 With Chest X Ray Using Resnet 18, densenet and loTenet In PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image classification of Chest X Rays in one of three classes: Normal, Viral Pneumonia, COVID-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset from COVID-19 Radiography Dataset on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version 1.3.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from models.lotenet import loTeNet\n",
    "from torchvision import transforms, datasets\n",
    "import pdb\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from models.Densenet import *\n",
    "import argparse\n",
    "torch.manual_seed(0)\n",
    "\n",
    "print('Using PyTorch version', torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['normal', 'viral', 'covid']\n",
    "root_dir = '/home/mashjunior/loTeNet_pytorch/Covid-19_images/COVID-19_Radiography/COVID-19 Radiography Database'\n",
    "source_dirs = ['normal', 'viral','covid']\n",
    "\n",
    "\n",
    "#if os.path.isdir(os.path.join(root_dir, source_dirs[1])):\n",
    "#    os.mkdir(os.path.join(root_dir, 'train'))\n",
    "\n",
    "#    for i, d in enumerate(source_dirs):\n",
    "#        os.rename(os.path.join(root_dir, d), os.path.join(root_dir, class_names[i]))\n",
    "\n",
    "#    for c in class_names:\n",
    "#        os.mkdir(os.path.join(root_dir, 'train', c))\n",
    "\n",
    "#    for c in class_names:\n",
    "#        images = [x for x in os.listdir(os.path.join(root_dir, c)) if x.lower().endswith('png')]\n",
    "#        selected_images = random.sample(images, 600)\n",
    "#        for image in selected_images:\n",
    "#            source_path = os.path.join(root_dir, c, image)\n",
    "#            target_path = os.path.join(root_dir, 'train', c, image)\n",
    "#            shutil.move(source_path, target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXRayDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_dirs,transform):\n",
    "        \n",
    "        def get_images(class_name):\n",
    "            images = [x for x in os.listdir(image_dirs[class_name]) if x.lower().endswith('png')]\n",
    "            print(f'Found {len(images)}{class_name}')\n",
    "            return images\n",
    "        \n",
    "        \n",
    "        self.images={}\n",
    "        self.class_names=['normal','viral','covid']\n",
    "        \n",
    "        for c in self.class_names:\n",
    "            self.images[c]=get_images(c)\n",
    "        self.image_dirs=image_dirs\n",
    "        self.transform=transform\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return sum([len(self.images[c]) for c in self.class_names])\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        class_name=random.choice(self.class_names)\n",
    "        index=index%len(self.images[class_name])\n",
    "        image_name=self.images[class_name][index]\n",
    "        image_path =os.path.join(self.image_dirs[class_name], image_name)\n",
    "        image=Image.open(image_path).convert('L')\n",
    "        image = self.transform(image)\n",
    "        image = image.type(torch.FloatTensor)/255.0\n",
    "        label = self.class_names.index(class_name)\n",
    "        #label = label.type(torch.FloatTensor)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class LIDC(Dataset):\n",
    "#\tdef __init__(self, rater=4, split='Train', data_dir = '/home/mashjunior/loTeNet_pytorch', transform=None):\n",
    "#\t\tsuper().__init__()\n",
    "\n",
    "#\t\tself.data_dir = data_dir\n",
    "#\t\tself.rater = rater\n",
    "#\t\tself.transform = transform\n",
    "#\t\tself.data, self.targets = torch.load(data_dir+split+'.pt')\n",
    "#\t\tself.targets = self.targets.type(torch.FloatTensor)\t\t   \n",
    "#\tdef __len__(self):\n",
    "#\t\treturn len(self.targets)\n",
    "\n",
    "#\tdef __getitem__(self, index):\n",
    "\n",
    "#\t\timage, label = self.data[index], self.targets[index]\n",
    "#\t\tif self.rater == 4:\n",
    "#\t\t\tlabel = (label.sum() > 2).type_as(self.targets)\n",
    "#\t\telse:\n",
    "#\t\t\tlabel = label[self.rater]\n",
    "#\t\timage = image.type(torch.FloatTensor)/255.0\n",
    "#\t\tif self.transform is not None:\n",
    "#\t\t\timage = self.transform(image)\n",
    "#\t\treturn image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images, labels =next(iter(dl_test))\n",
    "#show_images(images, labels, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globally load device identifier\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "     ### Evaluation funcntion for validation/testing\n",
    "\n",
    "    with torch.no_grad():\n",
    "        vl_acc = 0.\n",
    "        vl_loss = 0.\n",
    "        labelsNp = np.zeros(1)\n",
    "        predsNp = np.zeros(1)\n",
    "        model.eval()\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(loader):\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labelsNp = np.concatenate((labelsNp, labels.cpu().numpy()))\n",
    "\n",
    "            # Inference\n",
    "            scores = torch.sigmoid(model(inputs))\n",
    "\n",
    "            preds = scores\n",
    "            loss = loss_fun(scores, labels)\n",
    "            predsNp = np.concatenate((predsNp, preds.cpu().numpy()))\n",
    "            vl_loss += loss.item()\n",
    "\n",
    "        # Compute AUC over the full (valid/test) set\n",
    "        vl_acc = computeAuc(labelsNp[1:],predsNp[1:])\n",
    "        vl_loss = vl_loss/len(loader)\n",
    "\n",
    "    return vl_acc, vl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous initialization\n",
    "torch.manual_seed(1)\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--dense_net'], dest='dense_net', nargs=0, const=True, default=True, type=None, choices=None, help='Using Dense Net model', metavar=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument('--num_epochs', type=int, default=5, help='Number of training epochs')\n",
    "parser.add_argument('--batch_size', type=int, default=50, help='Batch size')\n",
    "parser.add_argument('--lr', type=float, default=5e-4, help='Learning rate')\n",
    "parser.add_argument('--l2', type=float, default=0, help='L2 regularisation')\n",
    "parser.add_argument('--aug', action='store_true', default=False, help='Use data augmentation')\n",
    "parser.add_argument('--data_path', type=str, default=root_dir,help='Path to data.')\n",
    "parser.add_argument('--bond_dim', type=int, default=5, help='MPS Bond dimension')\n",
    "parser.add_argument('--nChannel', type=int, default=1, help='Number of input channels')\n",
    "parser.add_argument('--dense_net', action='store_true', default=True, help='Using Dense Net model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = args.batch_size\n",
    "\n",
    "# LoTeNet parameters\n",
    "adaptive_mode = False \n",
    "periodic_bc   = False\n",
    "\n",
    "kernel = 2 # Stride along spatial dimensions\n",
    "output_dim = 3 # output dimension\n",
    " \n",
    "feature_dim = 2\n",
    "\n",
    "#logFile = time.strftime(\"%Y%m%d_%H_%M\")+'.txt'\n",
    "#makeLogFile(logFile)\n",
    "\n",
    "normTensor = 0.5*torch.ones(args.nChannel)\n",
    "### Data processing and loading...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data processing and loading....\n",
    "valid_transform = transforms.Compose([transforms.Normalize(mean=normTensor,std=normTensor)])\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize(size=(128,128)),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),\n",
    "                                      transforms.RandomRotation(20),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=normTensor,std=normTensor)])\n",
    "test_transform = valid_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600normal\n",
      "Found 600viral\n",
      "Found 600covid\n"
     ]
    }
   ],
   "source": [
    "train_dirs = {\n",
    "    'normal': root_dir + '/train/normal',\n",
    "    'viral':  root_dir + '/train/viral',\n",
    "    'covid': root_dir + '/train/covid'\n",
    "}\n",
    "train_dataset=ChestXRayDataset(train_dirs, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400normal\n",
      "Found 400viral\n",
      "Found 400covid\n"
     ]
    }
   ],
   "source": [
    "valid_dirs = {\n",
    "    'normal': root_dir + '/valid/normal',\n",
    "    'viral': root_dir + '/valid/viral',\n",
    "    'covid': root_dir + '/valid/covid'\n",
    "}\n",
    "\n",
    "valid_dataset = ChestXRayDataset(valid_dirs, valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100normal\n",
      "Found 100viral\n",
      "Found 100covid\n"
     ]
    }
   ],
   "source": [
    "test_dirs = {\n",
    "    'normal': root_dir + '/test/normal',\n",
    "    'viral': root_dir + '/test/viral',\n",
    "    'covid': root_dir + '/test/covid'\n",
    "}\n",
    "\n",
    "test_dataset = ChestXRayDataset(test_dirs, valid_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=train_dataset.class_names\n",
    "def show_images(images, labels, preds):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(1,6,i+1, xticks=[], yticks=[])\n",
    "        image=image.numpy().transpose((1,2,0))\n",
    "        mean=np.array([0.485,0.456,0.406])\n",
    "        std= np.array([0.229, 0.224, 0.225])\n",
    "        image=image*std/mean\n",
    "        image=np.clip(image,0.,1.)\n",
    "        plt.imshow(image)\n",
    "        col = 'green' if preds[i]==labels[i] else 'red'\n",
    "        plt.xlabel(f'{class_names[int(labels[i].numpy())]}')\n",
    "        plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color=col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training batches 36\n",
      "Num of validation batches 24\n",
      "Num of test batches 6\n"
     ]
    }
   ],
   "source": [
    "#batch_size=6\n",
    "dl_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dl_valid = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "dl_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "print('Num of training batches', len(dl_train))\n",
    "print('Num of validation batches', len(dl_valid))\n",
    "print('Num of test batches', len(dl_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliaze input dimensions\n",
    "dim = torch.ShortTensor(list(train_dataset[0][0].shape[1:]))\n",
    "nCh = int(train_dataset[0][0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([128, 128], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(nCh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0039)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = DenseNet(depth=40, growthRate=12, reduction=0.5,bottleneck=True,nClasses=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Densenet Baseline!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the models\n",
    "if not args.dense_net:\n",
    "\tprint(\"Using LoTeNet\")\n",
    "\tmodel = loTeNet(input_dim=dim, output_dim=output_dim, \n",
    "\t\t\t\t  nCh=nCh, kernel=kernel,\n",
    "\t\t\t\t  bond_dim=args.bond_dim, feature_dim=feature_dim,\n",
    "\t\t\t\t  adaptive_mode=adaptive_mode, periodic_bc=periodic_bc, virtual_dim=1)\n",
    "else:\n",
    "\tprint(\"Densenet Baseline!\")\n",
    "\tmodel = DenseNet(depth=40, growthRate=12, \n",
    "\t\t\t\t\treduction=0.5,bottleneck=True,nClasses=output_dim)\n",
    "model = loTeNet(input_dim=dim, output_dim=output_dim, \n",
    "\t\t\t\t  nCh=nCh, kernel=kernel,\n",
    "\t\t\t\t  bond_dim=args.bond_dim, feature_dim=feature_dim,\n",
    "\t\t\t\t  adaptive_mode=adaptive_mode, periodic_bc=periodic_bc, virtual_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose loss function and optimizer\n",
    "loss_fun = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, \n",
    "                             weight_decay=args.l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters:730980\n",
      "Maximum MPS bond dimension = 5\n",
      "Bond dim: 5\n",
      "Number of parameters:730980\n"
     ]
    }
   ],
   "source": [
    "nParam = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters:%d\"%(nParam))\n",
    "print(f\"Maximum MPS bond dimension = {args.bond_dim}\")\n",
    "\n",
    "print(\"Bond dim: %d\"%(args.bond_dim))\n",
    "print(\"Number of parameters:%d\"%(nParam),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Adam w/ learning rate = 5.0e-04\n",
      "Feature_dim: 2, nCh: 1, B:50\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Adam w/ learning rate = {args.lr:.1e}\")\n",
    "print(\"Feature_dim: %d, nCh: %d, B:%d\"%(feature_dim,nCh,batch_size))\n",
    "\n",
    "model = model.to(device)\n",
    "nValid = len(dl_valid)\n",
    "nTrain = len(dl_train)\n",
    "nTest = len(dl_test)\n",
    "\n",
    "maxAuc = 0\n",
    "minLoss = 1e3\n",
    "convCheck = 5\n",
    "convIter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[50, 16, 25, -1]' is invalid for input of size 576000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1a7a92de0263>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlabelsNp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelsNp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/james_tensor/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/loTeNet_pytorch/models/lotenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0miDim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \t\tx = x.unfold(2,iDim[0],iDim[0]).unfold(3,iDim[1],iDim[1]).reshape(b,\n\u001b[0;32m---> 86\u001b[0;31m \t\t\t\t\tself.nCh,(self.ker)**2,-1)\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[50, 16, 25, -1]' is invalid for input of size 576000"
     ]
    }
   ],
   "source": [
    "# Let's start training!\n",
    "for epoch in range(args.num_epochs):\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    #t = time.time()\n",
    "    model.train()\n",
    "    predsNp = np.zeros(1)\n",
    "    labelsNp = np.zeros(1)\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(dl_train):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labelsNp = np.concatenate((labelsNp, labels.cpu().numpy()))\n",
    "\n",
    "        scores = torch.sigmoid(model(inputs))\n",
    "\n",
    "        preds = scores\n",
    "        loss = loss_fun(scores, labels)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predsNp = np.concatenate((predsNp, preds.detach().cpu().numpy()))\n",
    "            running_loss += loss\n",
    "\n",
    "        # Backpropagate and update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 5 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, args.num_epochs, i+1, nTrain, loss.item()))\n",
    "\n",
    "    accuracy = computeAuc(labelsNp,predsNp)\n",
    "\n",
    "    # Evaluate on Validation set \n",
    "    with torch.no_grad():\n",
    "\n",
    "        vl_acc, vl_loss = evaluate(dl_valid)\n",
    "        if vl_acc > maxAuc or vl_loss < minLoss:\n",
    "            if vl_loss < minLoss:\n",
    "                minLoss = vl_loss\n",
    "            if vl_acc > maxAuc:\n",
    "                ### Predict on test set\n",
    "                ts_acc, ts_loss = evaluate(dl_test)\n",
    "                maxAuc = vl_acc\n",
    "                print('New Max: %.4f'%maxAuc)\n",
    "                print('Test Set Loss:%.4f\tAuc:%.4f'%(ts_loss, ts_acc))\n",
    "                print('Test Set Loss:%.4f\tAuc:%.4f'%(ts_loss, ts_acc))\n",
    "            convEpoch = epoch\n",
    "            convIter = 0\n",
    "        else:\n",
    "            convIter += 1\n",
    "        if convIter == convCheck:\n",
    "            if not args.dense_net:\n",
    "                print(\"MPS\")\n",
    "            else:\n",
    "                print(\"DenseNet\")\n",
    "            print(\"Converged at epoch:%d with AUC:%.4f\"%(convEpoch+1,maxAuc))\n",
    "\n",
    "            break\n",
    "#\twriteLog(logFile, epoch, running_loss/nTrain, accuracy,\n",
    "#\t\t\tvl_loss, vl_acc, time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
